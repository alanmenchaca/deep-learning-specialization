## deep-learning-specialization
The Deep Learning Specialization is a foundational program that will help us understand the capabilities, challenges, and consequences of deep learning and prepare us to participate in the development of leading-edge AI technology. 

In this Specialization, we will build and train neural network architectures such as Convolutional Neural Networks, Recurrent Neural Networks, LSTMs, Transformers, and learn how to make them better with strategies such as Dropout, BatchNorm, Xavier/He initialization, and more. We will get ready to master theoretical concepts and their industry applications using Python and TensorFlow and tackle real-world cases such as speech recognition, music synthesis, chatbots, machine translation, natural language processing, and more.

There are 5 courses in this Specialized Program:

### Course 1: [Neural Networks Deep Learning](https://github.com/alanmenchaca/deep-learning-specialization/tree/main/%5BC01%5D%20Neural%20Networks%20and%20Deep%20Learning)
In the first course of the Deep Learning Specialization, we will study the foundational concept of neural networks and deep learning. 

* **Week 1 - Introduction to Deep Learning:** Analyze the major trends driving the rise of deep learning, and give examples of where and how it is applied today.
* [**Week 2 - Neural Networks Basics:**]() Set up a machine learning problem with a neural network mindset and use vectorization to speed up your models.
* [**Week 3 - Shallow Neural Networks:**]() Build a neural network with one hidden layer, using forward propagation and backpropagation.
* [**Week 4 - Deep Neural Networks:**]() Analyze the key computations underlying deep learning, then use them to build and train deep neural networks for computer vision tasks.

### Course 2: [Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization]()
In the second course of the Deep Learning Specialization, we will open the deep learning black box to understand the processes that drive performance and generate good results systematically. 

* [**Week 1 - Practical Aspects of Deep Learning:**]() Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid model overfitting, then apply gradient checking to identify errors in a fraud detection model.
* [**Week 2 - Optimization Algorithms:**]() Develop your deep learning toolbox by adding more advanced optimizations, random minibatching, and learning rate decay scheduling to speed up your models.
* [**Week 3 - Hyperparameter Tuning, Batch Normalization and Programming Frameworks:**]() Explore TensorFlow, a deep learning framework that allows you to build neural networks quickly and easily, then train a neural network on a TensorFlow dataset.

### Disclaimer
The solutions to the assignments uploaded here are **only for reference**.
